# -*- coding: utf-8 -*-
"""Project_fianl.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OqHboyZa-T2iDhBSQSKwrtWUrQ0JZpGz

# New Section
"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
import string
from nltk.tokenize import RegexpTokenizer
from nltk.corpus import stopwords
import nltk
nltk.download('stopwords')
import seaborn as sns
# from plotly.offline import init_notebook_mode, iplot
import plotly.offline as py
import plotly.graph_objs as go
from sklearn.model_selection import train_test_split
import category_encoders as ce

# %matplotlib inline

from mlxtend.plotting import plot_decision_regions
from mlxtend.plotting import category_scatter


import graphviz
from sklearn.tree import export_graphviz
from sklearn.datasets import make_blobs
from sklearn.datasets import make_moons
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_breast_cancer
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score, accuracy_score


df = pd.read_csv('ramen-ratings.csv')

df.head(10)

"""# Data Preparation """



df.describe()

df.info()

df['Stars'].isnull().value_counts()

df.Style.unique()

df.Style.mode()

df.Style.replace(np.nan,'Pack',inplace=True)

df.Stars.unique()

df.Stars.replace('Unrated',np.nan,inplace=True)

df['Stars'] = df['Stars'].astype(float)

df.Stars.unique()

df.Stars.mean()

df.Stars.replace(np.nan,3.65,inplace=True)

"""# Data Exploration"""

df.loc[:,'Stars'].describe()

df.Stars.value_counts()

(df.Stars.value_counts() / df.Stars.size).plot(kind='bar', title='Target Distribution')


df.Brand.value_counts()

df_ave_stars= df[['Country','Stars']].groupby('Country').mean().sort_values('Stars',ascending=False).reset_index()

df_sorted = df.groupby('Country').count().sort_values('Brand',ascending=False).Brand.reset_index()

df_joined = pd.merge(df_sorted, df_ave_stars, how='inner')

plt.figure(figsize=(15,5))
plt.xticks(rotation=90)
plt.ylabel('Average Ramen Rating')
sizes = dict(zip(df_joined.Country,df_joined.Brand.values*10))
sns.scatterplot('Country','Stars', data=df_joined,
                size='Country',
                hue='Country',
                sizes=sizes,
                legend=False,
                alpha=0.2,
                edgecolor='yellow',
                )

plt.figure(figsize=(15,5))
plt.grid()
plt.hist(df.Stars,bins=20,edgecolor='k',align='mid')
plt.xlabel('Stars')
plt.ylabel('Number')

plt.figure(figsize=(15,5))
plt.grid()
plt.hist(df.Country,bins=20,edgecolor='k',align='mid')
plt.xlabel('Country')
plt.ylabel('Number')

df_ave_stars.set_index('Country').join(df_sorted.set_index('Country'))

df.groupby('Style').mean().sort_values('Stars',ascending=False).Stars.reset_index()

data = df.groupby('Style').mean().sort_values('Stars',ascending=False).Stars.reset_index()



sns.boxplot(df.Style,df.Stars,palette ='Set2')
plt.ylabel('Average Ramen Rating')
plt.show()

df.Brand.unique()

df.head(5)

ccount = df.groupby('Country').count().sort_values('Brand',ascending=False).Brand



df.Brand.unique()

len(df.Brand.unique())

len(df.Country.unique())

df.Country.unique()

df.head()

"""# Feature Engineering"""

tokenizer = RegexpTokenizer(r'\w+')
df.loc[:,'Variety'] = df.loc[:,'Variety'].apply(lambda x: tokenizer.tokenize(x.lower()))

from nltk.corpus import stopwords
specified_extra = ['noodles','noodle','flavour','artificial','ramen','instant','flavor','sauce','cup','bowl','rice','restaurant','soup','mi']
def remove_stopwords(text):
    english_words = [w for w in text if w not in stopwords.words('english')]
    additional_words = [w for w in english_words if w not in specified_extra]
    return additional_words

df.loc[:,'Variety'] = df.loc[:,'Variety'].apply(lambda x: remove_stopwords(x))

df.loc[:,'Variety'] = df.loc[:,'Variety'].apply(lambda x: list(set(x)))

df.loc[:,'Variety'] = df.loc[:,'Variety'].apply(lambda x:" ".join(x))

df.loc[:,'Variety'].value_counts()


from sklearn.feature_extraction.text import CountVectorizer

max_feature_length = 10
top_words = []

bow_transformer = CountVectorizer(max_features=max_feature_length,ngram_range=(1,1)).fit(df.loc[:,'Variety'])
bow = bow_transformer.transform([' '.join(df.loc[:,'Variety'].values)])#This joins all the words in all the rows 
word_list = bow_transformer.get_feature_names()
count_list = bow.toarray().sum(axis=0) 
top_counts = pd.DataFrame(zip(word_list,count_list),columns=['term','count',])
top_counts.sort_values('count',axis=0,inplace=True, ascending=False)


df.Variety.apply(lambda y: np.array([x for x in y.split() if x in top_counts.term.values]))

df['flavour'] = df.Variety.apply(lambda y: np.array([x for x in y.split() if x in top_counts.term.values]))
df['flavour'] = df['flavour'].apply(lambda x :" ".join(x))
df['flavour'].replace('tom','tom yum',inplace=True) # Change tom to tom yum

"""Tom Yum is a simple, but flavorful, soup made with fresh lemongrass, kaffir lime leaves, fish sauce, chiles, and proteinâ€¦ Usually shrimp. And in Thailand, it's everywhere."""


y = df['Style']

x = df.drop(columns=['Review #','Style','Variety','Top Ten' ])


from sklearn import preprocessing 
le = preprocessing.LabelEncoder()

y.isnull().values.any()

y.unique()

y.value_counts()

y = le.fit_transform(y)


y1 = le.fit_transform(y)

x1 = x.apply(le.fit_transform)

x.describe()

encoder = ce.BaseNEncoder(cols=['Brand'],return_df=True,base=5)
brand_encoded = encoder.fit_transform(df.Brand)
brand_encoded = brand_encoded.drop(columns=['Brand_0'])

encoder = ce.BaseNEncoder(cols=['Country'],return_df=True,base=5)
country_encoded = encoder.fit_transform(df.Country)
country_encoded = country_encoded.drop(columns=['Country_0'])

encoder = ce.BaseNEncoder(cols=['flavour'],return_df=True,base=5)
flavour_encoded = encoder.fit_transform(df.flavour)
flavour_encoded = flavour_encoded.drop(columns=['flavour_0'])

final_cleaned = flavour_encoded.join(brand_encoded).join(country_encoded)
final_cleaned['Stars'] = df.Stars

x = final_cleaned


x_train, x_test, y_train,  y_test = train_test_split(x, y,test_size=0.3, random_state=2021 )


print('Train', x_train.shape, y_train.shape)
print('Test', x_test.shape, y_test.shape)

# Tell pandas to make a copy when we create the new dataframe (prevents SettingWithCopyWarning)
x_train, x_test, y_train, y_test = x_train.copy(), x_test.copy(), y_train.copy(), y_test.copy()

print('Train_copy', x_train.copy().shape, y_train.copy().shape)
print('Test_copy', x_test.copy().shape, y_test.copy().shape)

import scikitplot as skplt
rf = RandomForestClassifier()
rf.fit(x, y)


num_trees = range(10,50)
scores = []
for num_trees_ in num_trees:
    rf = RandomForestClassifier(n_estimators=num_trees_, random_state=2020)
    rf.fit(x_train, y_train)
    score_aux = rf.score(x_test, y_test)
    scores.append(score_aux)
plt.plot(num_trees, scores)

num_trees = range(50,100)
scores = []
for num_trees_ in num_trees:
    rf = RandomForestClassifier(n_estimators=num_trees_, random_state=2020)
    rf.fit(x_train, y_train)
    score_aux = rf.score(x_test, y_test)
    scores.append(score_aux)
plt.plot(num_trees, scores)

num_trees = range(60,70)
scores = []
for num_trees_ in num_trees:
    rf = RandomForestClassifier(n_estimators=num_trees_, random_state=2020)
    rf.fit(x_train, y_train)
    scores.append(rf.score(x_test, y_test))
plt.plot(num_trees, scores)

rf = RandomForestClassifier(n_estimators=64)
rf.fit(x_train, y_train)
rf.score(x_test, y_test)


import scikitplot as skplt

skplt.estimators.plot_feature_importances(rf, feature_names=x.columns, figsize=(15, 10), x_tick_rotation=90)


# instantiate
svm_ = SVC(C=1000)
# fit
svm_.fit(x_train, y_train)

svm_.score(x_test, y_test)

knn_ = KNeighborsClassifier(n_neighbors = 100)
# fit
knn_.fit(x_train, y_train)

knn_.score(x_test, y_test)

lr = LogisticRegression(solver='lbfgs')
# fit
lr.fit(x_train, y_train)

lr.score(x_test, y_test)

x_train.drop(['flavour_1','Country_1'],axis=1,inplace=True)

x_test.drop(['flavour_1','Country_1'],axis=1,inplace=True)

lr = LogisticRegression(solver='lbfgs')
# fit
lr.fit(x_train, y_train)

lr.score(x_test, y_test)

rf = RandomForestClassifier(n_estimators=10, random_state=2020)
rf.fit(x_train, y_train)

y_pred = rf.predict(x_test)

confusion_matrix(y_test, y_pred)

skplt.metrics.plot_confusion_matrix(y_test, y_pred)

x1_train, x1_test, y1_train,  y1_test = train_test_split(x1, y1,test_size=0.3, random_state=2021 )

rf1 = RandomForestClassifier(n_estimators=64)
rf1.fit(x1_train, y1_train)

rf1.score(x1_test, y1_test)

skplt.estimators.plot_feature_importances(rf1, feature_names=x1.columns, figsize=(15, 10), x_tick_rotation=90)

rf1 = RandomForestClassifier(n_estimators=10, random_state=2020)
rf1.fit(x1_train, y1_train)

y1_pred = rf1.predict(x1_test)

confusion_matrix(y1_test, y1_pred)
skplt.metrics.plot_confusion_matrix(y1_test, y1_pred)


accuracy_score(y_test, y_pred)
accuracy_score(y1_test, y1_pred)

print(classification_report(y_test, y_pred))
print(classification_report(y1_test, y1_pred))